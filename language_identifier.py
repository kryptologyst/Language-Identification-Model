"""
Modern Language Identification Model
Using state-of-the-art techniques including transformers and neural networks
"""

import pandas as pd
import numpy as np
import pickle
import json
from typing import List, Dict, Tuple, Optional
import logging
from pathlib import Path

# Core ML libraries
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

# Deep learning libraries
try:
    import torch
    import transformers
    from transformers import AutoTokenizer, AutoModel
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("Transformers not available. Install with: pip install transformers torch")

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

# Web framework
try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LanguageIdentifier:
    """
    Modern Language Identification System with multiple model options
    """
    
    def __init__(self, model_type: str = "ensemble"):
        self.model_type = model_type
        self.models = {}
        self.vectorizer = None
        self.tokenizer = None
        self.transformer_model = None
        self.languages = []
        self.confidence_threshold = 0.7
        
    def load_mock_database(self) -> pd.DataFrame:
        """Load extensive multilingual dataset"""
        # Extended dataset with more languages and examples
        data = {
            'text': [
                # English
                'Hello, how are you today?', 'The weather is beautiful today.',
                'I love programming and machine learning.', 'What time is it?',
                'This is a wonderful day.', 'How can I help you?',
                
                # French
                'Bonjour, comment allez-vous?', 'Le temps est magnifique aujourd\'hui.',
                'J\'adore la programmation et l\'intelligence artificielle.', 'Quelle heure est-il?',
                'C\'est une merveilleuse journ√©e.', 'Comment puis-je vous aider?',
                
                # Spanish
                'Hola, ¬øc√≥mo est√°s hoy?', 'El clima est√° hermoso hoy.',
                'Me encanta la programaci√≥n y el aprendizaje autom√°tico.', '¬øQu√© hora es?',
                'Es un d√≠a maravilloso.', '¬øC√≥mo puedo ayudarte?',
                
                # German
                'Hallo, wie geht es dir heute?', 'Das Wetter ist heute wundersch√∂n.',
                'Ich liebe Programmierung und maschinelles Lernen.', 'Wie sp√§t ist es?',
                'Das ist ein wundervoller Tag.', 'Wie kann ich dir helfen?',
                
                # Italian
                'Ciao, come stai oggi?', 'Il tempo √® bellissimo oggi.',
                'Amo la programmazione e l\'apprendimento automatico.', 'Che ore sono?',
                '√à una giornata meravigliosa.', 'Come posso aiutarti?',
                
                # Portuguese
                'Ol√°, como voc√™ est√° hoje?', 'O tempo est√° lindo hoje.',
                'Eu amo programa√ß√£o e aprendizado de m√°quina.', 'Que horas s√£o?',
                '√â um dia maravilhoso.', 'Como posso ajud√°-lo?',
                
                # Japanese
                '„Åì„Çì„Å´„Å°„ÅØ„ÄÅ‰ªäÊó•„ÅØ„Å©„ÅÜ„Åß„Åô„ÅãÔºü', '‰ªäÊó•„ÅØÂ§©Ê∞ó„ÅåÁæé„Åó„ÅÑ„Åß„Åô„ÄÇ',
                '„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„Å®Ê©üÊ¢∞Â≠¶Áøí„ÅåÂ§ßÂ•Ω„Åç„Åß„Åô„ÄÇ', '‰ªä‰ΩïÊôÇ„Åß„Åô„ÅãÔºü',
                'Á¥†Êô¥„Çâ„Åó„ÅÑ‰∏ÄÊó•„Åß„Åô„ÄÇ', '„Å©„ÅÆ„Çà„ÅÜ„Å´„ÅäÊâã‰ºù„ÅÑ„Åß„Åç„Åæ„Åô„ÅãÔºü',
                
                # Korean
                'ÏïàÎÖïÌïòÏÑ∏Ïöî, Ïò§ÎäòÏùÄ Ïñ¥Îñ†ÏÑ∏Ïöî?', 'Ïò§Îäò ÎÇ†Ïî®Í∞Ä ÏïÑÎ¶ÑÎãµÏäµÎãàÎã§.',
                'ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÍ≥º Î®∏Ïã†Îü¨ÎãùÏùÑ ÏÇ¨ÎûëÌï©ÎãàÎã§.', 'ÏßÄÍ∏à Î™á ÏãúÏù∏Í∞ÄÏöî?',
                'Î©ãÏßÑ ÌïòÎ£®ÏûÖÎãàÎã§.', 'Ïñ¥ÎñªÍ≤å ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?',
                
                # Russian
                '–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞ —Å–µ–≥–æ–¥–Ω—è?', '–°–µ–≥–æ–¥–Ω—è –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –ø–æ–≥–æ–¥–∞.',
                '–Ø –ª—é–±–ª—é –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ.', '–ö–æ—Ç–æ—Ä—ã–π —á–∞—Å?',
                '–≠—Ç–æ –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π –¥–µ–Ω—å.', '–ö–∞–∫ —è –º–æ–≥—É –ø–æ–º–æ—á—å?',
                
                # Hindi
                '‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§ú ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?', '‡§Ü‡§ú ‡§Æ‡•å‡§∏‡§Æ ‡§¨‡§π‡•Å‡§§ ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§π‡•à‡•§',
                '‡§Æ‡•Å‡§ù‡•á ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à‡•§', '‡§Ö‡§≠‡•Ä ‡§ï‡§ø‡§§‡§®‡§æ ‡§¨‡§ú‡§æ ‡§π‡•à?',
                '‡§Ø‡§π ‡§è‡§ï ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ ‡§¶‡§ø‡§® ‡§π‡•à‡•§', '‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç?',
                
                # Chinese (Simplified)
                '‰Ω†Â•ΩÔºå‰Ω†‰ªäÂ§©ÊÄé‰πàÊ†∑Ôºü', '‰ªäÂ§©Â§©Ê∞îÂæàÁæé„ÄÇ',
                'ÊàëÂñúÊ¨¢ÁºñÁ®ãÂíåÊú∫Âô®Â≠¶‰π†„ÄÇ', 'Áé∞Âú®Âá†ÁÇπ‰∫ÜÔºü',
                'ËøôÊòØÁæéÂ•ΩÁöÑ‰∏ÄÂ§©„ÄÇ', 'ÊàëÊÄé‰πàËÉΩÂ∏ÆÂä©‰Ω†Ôºü',
                
                # Arabic
                'ŸÖÿ±ÿ≠ÿ®ÿßÿå ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉ ÿßŸÑŸäŸàŸÖÿü', 'ÿßŸÑÿ∑ŸÇÿ≥ ÿ¨ŸÖŸäŸÑ ÿßŸÑŸäŸàŸÖ.',
                'ÿ£ÿ≠ÿ® ÿßŸÑÿ®ÿ±ŸÖÿ¨ÿ© ŸàÿßŸÑÿ™ÿπŸÑŸÖ ÿßŸÑÿ¢ŸÑŸä.', 'ŸÉŸÖ ÿßŸÑÿ≥ÿßÿπÿ© ÿßŸÑÿ¢ŸÜÿü',
                'Ÿáÿ∞ÿß ŸäŸàŸÖ ÿ±ÿßÿ¶ÿπ.', 'ŸÉŸäŸÅ ŸäŸÖŸÉŸÜŸÜŸä ŸÖÿ≥ÿßÿπÿØÿ™ŸÉÿü',
                
                # Dutch
                'Hallo, hoe gaat het vandaag?', 'Het weer is prachtig vandaag.',
                'Ik hou van programmeren en machine learning.', 'Hoe laat is het?',
                'Het is een geweldige dag.', 'Hoe kan ik je helpen?',
                
                # Swedish
                'Hej, hur m√•r du idag?', 'V√§dret √§r vackert idag.',
                'Jag √§lskar programmering och maskininl√§rning.', 'Vad √§r klockan?',
                'Det √§r en underbar dag.', 'Hur kan jag hj√§lpa dig?',
            ],
            'language': [
                'English', 'English', 'English', 'English', 'English', 'English',
                'French', 'French', 'French', 'French', 'French', 'French',
                'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish',
                'German', 'German', 'German', 'German', 'German', 'German',
                'Italian', 'Italian', 'Italian', 'Italian', 'Italian', 'Italian',
                'Portuguese', 'Portuguese', 'Portuguese', 'Portuguese', 'Portuguese', 'Portuguese',
                'Japanese', 'Japanese', 'Japanese', 'Japanese', 'Japanese', 'Japanese',
                'Korean', 'Korean', 'Korean', 'Korean', 'Korean', 'Korean',
                'Russian', 'Russian', 'Russian', 'Russian', 'Russian', 'Russian',
                'Hindi', 'Hindi', 'Hindi', 'Hindi', 'Hindi', 'Hindi',
                'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese', 'Chinese',
                'Arabic', 'Arabic', 'Arabic', 'Arabic', 'Arabic', 'Arabic',
                'Dutch', 'Dutch', 'Dutch', 'Dutch', 'Dutch', 'Dutch',
                'Swedish', 'Swedish', 'Swedish', 'Swedish', 'Swedish', 'Swedish',
            ]
        }
        
        df = pd.DataFrame(data)
        self.languages = df['language'].unique().tolist()
        logger.info(f"Loaded dataset with {len(df)} samples and {len(self.languages)} languages")
        return df
    
    def prepare_features(self, texts: List[str], method: str = "tfidf") -> np.ndarray:
        """Prepare features using different methods"""
        if method == "tfidf":
            if self.vectorizer is None:
                self.vectorizer = TfidfVectorizer(
                    analyzer='char', 
                    ngram_range=(1, 4),
                    max_features=5000,
                    lowercase=True
                )
                return self.vectorizer.fit_transform(texts)
            else:
                return self.vectorizer.transform(texts)
        
        elif method == "transformer" and TRANSFORMERS_AVAILABLE:
            if self.tokenizer is None:
                self.tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')
                self.transformer_model = AutoModel.from_pretrained('xlm-roberta-base')
            
            # Tokenize and get embeddings
            inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128)
            with torch.no_grad():
                outputs = self.transformer_model(**inputs)
                # Use mean pooling
                embeddings = outputs.last_hidden_state.mean(dim=1)
                return embeddings.numpy()
        
        else:
            raise ValueError(f"Unsupported feature method: {method}")
    
    def train_models(self, df: pd.DataFrame):
        """Train multiple models for ensemble prediction"""
        logger.info("Training language identification models...")
        
        # Prepare data
        X = self.prepare_features(df['text'].tolist())
        y = df['language']
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Train different models
        models = {
            'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),
            'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'neural_network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
        }
        
        for name, model in models.items():
            logger.info(f"Training {name}...")
            model.fit(X_train, y_train)
            
            # Evaluate
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            logger.info(f"{name} accuracy: {accuracy:.3f}")
            
            self.models[name] = model
        
        # Store test data for evaluation
        self.X_test = X_test
        self.y_test = y_test
        
        logger.info("Model training completed!")
    
    def predict(self, text: str) -> Dict:
        """Predict language with confidence scores"""
        if not self.models:
            raise ValueError("Models not trained yet!")
        
        # Prepare features
        X = self.prepare_features([text])
        
        predictions = {}
        confidences = {}
        
        for name, model in self.models.items():
            pred = model.predict(X)[0]
            if hasattr(model, 'predict_proba'):
                proba = model.predict_proba(X)[0]
                confidence = max(proba)
            else:
                confidence = 1.0
            
            predictions[name] = pred
            confidences[name] = confidence
        
        # Ensemble prediction (majority vote)
        ensemble_pred = max(set(predictions.values()), key=list(predictions.values()).count)
        ensemble_confidence = np.mean(list(confidences.values()))
        
        return {
            'predicted_language': ensemble_pred,
            'confidence': ensemble_confidence,
            'individual_predictions': predictions,
            'individual_confidences': confidences,
            'is_confident': ensemble_confidence >= self.confidence_threshold
        }
    
    def batch_predict(self, texts: List[str]) -> List[Dict]:
        """Predict languages for multiple texts"""
        return [self.predict(text) for text in texts]
    
    def evaluate_model(self) -> Dict:
        """Evaluate model performance"""
        if not self.models or not hasattr(self, 'X_test'):
            raise ValueError("Model not trained yet!")
        
        results = {}
        
        for name, model in self.models.items():
            y_pred = model.predict(self.X_test)
            accuracy = accuracy_score(self.y_test, y_pred)
            results[name] = {
                'accuracy': accuracy,
                'classification_report': classification_report(self.y_test, y_pred, output_dict=True)
            }
        
        return results
    
    def visualize_confusion_matrix(self, model_name: str = 'logistic_regression'):
        """Create confusion matrix visualization"""
        if model_name not in self.models:
            raise ValueError(f"Model {model_name} not found!")
        
        model = self.models[model_name]
        y_pred = model.predict(self.X_test)
        
        cm = confusion_matrix(self.y_test, y_pred, labels=self.languages)
        
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', 
                   xticklabels=self.languages, 
                   yticklabels=self.languages,
                   cmap='Blues')
        plt.title(f"Confusion Matrix - {model_name.replace('_', ' ').title()}")
        plt.xlabel("Predicted Language")
        plt.ylabel("True Language")
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.show()
    
    def save_model(self, filepath: str):
        """Save trained models and vectorizer"""
        model_data = {
            'models': self.models,
            'vectorizer': self.vectorizer,
            'languages': self.languages,
            'model_type': self.model_type
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        logger.info(f"Model saved to {filepath}")
    
    def load_model(self, filepath: str):
        """Load trained models and vectorizer"""
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        self.models = model_data['models']
        self.vectorizer = model_data['vectorizer']
        self.languages = model_data['languages']
        self.model_type = model_data['model_type']
        
        logger.info(f"Model loaded from {filepath}")


def main():
    """Main function to demonstrate the language identifier"""
    # Initialize the language identifier
    identifier = LanguageIdentifier()
    
    # Load data and train models
    df = identifier.load_mock_database()
    identifier.train_models(df)
    
    # Test predictions
    test_texts = [
        "Hello, how are you?",
        "Bonjour, comment allez-vous?",
        "Hola, ¬øc√≥mo est√°s?",
        "„Åì„Çì„Å´„Å°„ÅØ„ÄÅÂÖÉÊ∞ó„Åß„Åô„ÅãÔºü",
        "ÏïàÎÖïÌïòÏÑ∏Ïöî, Ïûò ÏßÄÎÇ¥ÏÑ∏Ïöî?"
    ]
    
    print("\n" + "="*60)
    print("LANGUAGE IDENTIFICATION RESULTS")
    print("="*60)
    
    for text in test_texts:
        result = identifier.predict(text)
        print(f"\nüìÑ Text: \"{text}\"")
        print(f"üî§ Predicted Language: {result['predicted_language']}")
        print(f"üìä Confidence: {result['confidence']:.3f}")
        print(f"‚úÖ Confident: {'Yes' if result['is_confident'] else 'No'}")
    
    # Evaluate models
    print("\n" + "="*60)
    print("MODEL EVALUATION")
    print("="*60)
    
    evaluation = identifier.evaluate_model()
    for model_name, metrics in evaluation.items():
        print(f"\n{model_name.replace('_', ' ').title()}:")
        print(f"  Accuracy: {metrics['accuracy']:.3f}")
    
    # Visualize confusion matrix
    identifier.visualize_confusion_matrix()
    
    # Save model
    identifier.save_model('language_identifier_model.pkl')


if __name__ == "__main__":
    main()
